---
title: "Scrape MarineCadastre.gov for Datasets"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = F, echo = TRUE, message = F, warning = F)
```

## Install phantomjs on ubuntu

```bash
uname -a
# Linux d85016b9068e 4.15.0-99-generic #100-Ubuntu SMP Wed Apr 22 20:32:56 UTC 2020 x86_64 GNU/Linux
```

```bash
sudo apt-get update
sudo apt-get install -y build-essential chrpath libssl-dev libxft-dev libfreetype6 libfreetype6-dev libfontconfig1 libfontconfig1-dev
```

Get latest version at https://phantomjs.org/download.html.

```bash
cd ~
export PHANTOM_JS="phantomjs-2.1.1-linux-x86_64"
wget https://bitbucket.org/ariya/phantomjs/downloads/$PHANTOM_JS.tar.bz2
sudo tar xvjf $PHANTOM_JS.tar.bz2
sudo mv $PHANTOM_JS /usr/local/share
sudo ln -sf /usr/local/share/$PHANTOM_JS/bin/phantomjs /usr/local/bin
# I managed to solve this error by creating the OPENSSL_CONF variable.
# https://github.com/bazelbuild/rules_closure/pull/353#issuecomment-619092111
sudo apt install openssl
export OPENSSL_CONF=/etc/ssl/
phantomjs --version
```

Now, It should have PhantomJS properly on your system.

## Scrape for Datasets

Scrape datasets with links for downloads and metadata from [marinecadastre.gov/data](https://marinecadastre.gov/data/) using the R package `rvest` (see `vignette("selectorgadget")`).

- [rvest: easy web scraping with R | RStudio Blog](https://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/)

```{r init, eval=T}
librarian::shelf(
  DT, dplyr, fs, glue, purrr, readr, rvest, stringr, tibble)
  # tidyverse, webshot)

url_mc        <- "https://marinecadastre.gov/data/"
dir_pfx       <- "/Users/bbest/My Drive/projects/offhab/data"
dir_mc        <- glue("{dir_pfx}/marinecadastre.gov")
# date_mc      <- Sys.Date()
date_mc       <- as.Date("2022-08-04")
mc_pfx        <- glue("{dir_mc}_datasets_{date_mc}")
mc_csv        <- glue("{mc_pfx}.csv")
mc_paths_csv  <- glue("{mc_pfx}_paths.csv")
mc_themes_csv <- glue("{mc_pfx}_themes.csv")
mc_nothemes_csv <- glue("{mc_pfx}_no-themes.csv")
mc_supplthemes_csv <- glue("{mc_pfx}_themes-supplemental.csv")

dir.create(dir_mc, showWarnings = F)
```

```{r scrape}
get_page = function(url, js='mc_scrape.js', html='mc_scraped.html'){
  # url = url_mc; js='scrape.js'; html='scraped.html'
  
  # write javascript for feeding to phantomjs for obtaining rendered html
  write(paste0(
  "var url ='", url, "';
  var page = new WebPage(); var fs = require('fs');
  // open page, wait 5000 miliseconds, write html
  page.open(url, function (status) {
    just_wait();
  });
  function just_wait() {
    setTimeout(function() {
      fs.write('", html, "', page.content, 'w');
      phantom.exit();
    }, 5000);
  }
  "), js)
  bin_phantom <- webshot:::find_phantom(quiet = T)
  # cd /share/github/apps; /usr/local/bin/phantomjs scrape.js
  #system("./phantomjs scrape_dow_30.js") ## apply scraping 
  #webshot:::phantom_run(js)
  #bin_phantom <- "/usr/local/bin/phantomjs"
  system(glue("'{bin_phantom}' {js}"))
  return(html)
}

# library(V8)
# emailjs <- read_html(link) %>% html_nodes('li') %>% html_nodes('script') %>% html_text()
# # Create a new v8 context
# ct <- v8()
# #parse the html content from the js output and print it as text
# read_html(ct$eval(gsub('document.write','',emailjs))) %>% 
#  html_text()

if (!file.exists(mc_csv)){
  h = get_page(url_mc) %>%
    read_html()
  # h = read_html(url_mc)
  #unlink(c('scrape.js','scraped.html'))
  nodes = h %>% html_nodes('div.mc-panel-layer')
  
  d = tibble(
    #node         = h %>% html_nodes('div.mc-panel-layer'))
    title        = nodes %>% html_nodes('h4') %>% html_text(trim=T),
    description  = nodes %>% html_nodes('div.panel-body') %>% html_text(trim=T),
    provider     = nodes %>% html_nodes('p') %>% html_text(trim=T),
    provider_url = nodes %>% html_nodes('p a') %>% html_attr('href'),
    downloads    = map(nodes, function(x) html_nodes(
      x, 'a[analytics-event="Download"]') %>% 
        html_attr('href')),
    metadatas    = map(nodes, function(x) html_nodes(
      x, 'li[ng-repeat="metadata in layer.Metadata[0].MetadataInfo"] > a') %>% 
        html_attr('href')),
    downloads_piped = map_chr(downloads, function(x) paste(x, collapse='|')),
    downloads_n     = map_int(downloads, length),
    metadatas_piped = map_chr(metadatas, function(x) paste(x, collapse='|')),
    metadatas_n     = map_int(metadatas, length)) %>% 
    select(-downloads, -metadatas) %>% 
    rename(
      downloads = downloads_piped,
      metadatas = metadatas_piped)
    
  #write_csv(d %>% select(-node, -downloads, -metadatas), mc_csv)
  # write_csv(d %>% select(-downloads, -metadatas), mc_csv)
  write_csv(d, mc_csv)
  #file.copy(mc_csv, mc_csv2)
  # file.copy(mc_csv, mc_csv_gh)
}
```

```{r, eval=T}
read_csv(mc_csv) %>%
  select(-downloads, -metadatas) %>%
  # select(-description) %>%
  datatable(options = list(pageLength = 50))
```

## Get Themes with Selenium

* [Basics • RSelenium](https://docs.ropensci.org/RSelenium/articles/basics.html)

In Terminal, with Docker on:

```bash
docker run -d -p 4445:4444 --name selenium selenium/standalone-firefox:2.53.1
```

```{r, eval=F}
librarian::shelf(
  RSelenium)

dir.create("tmp", showWarnings = F)

rd <- remoteDriver(
  remoteServerAddr = "localhost",
  port = 4445L,
  browserName = "firefox")

rd$open()
rd$navigate("https://marinecadastre.gov/data/")
rd$screenshot(display = T)
e_show_themes <- rd$findElement(
  "css selector",
  '[ng-show|="themeTags.length > limit"]')
e_show_themes$clickElement()
rd$screenshot(display = T)
e_themes <- rd$findElements(
  "css selector",
  '[ng-click^="toggleThemeLayer(themeTag)"]')
for (e in e_themes){ # e = e_themes[[1]]
  theme <- e$getElementText()[[1]]
  
  e$clickElement()
  rd$screenshot(display = T)
  
  # save to txt
  src <- rd$getPageSource()[[1]]
  htm <- glue("tmp/{theme}.html")
  csv <- glue("tmp/{theme}.csv")
  
  writeLines(src, htm)
  nodes = read_html(htm) %>% 
    html_nodes('div.mc-panel-layer')
  d = tibble(
    title  = nodes %>% html_nodes('h4') %>% html_text(trim=T))
  write_csv(d, csv)

  e$clickElement()
  rd$screenshot(display = T)
}

rd$close
```

In Terminal, turn off Docker container:

```bash
docker stop selenium
```

```{r}
redo = F

d_mc <- read_csv(mc_csv)
if (!"id" %in% names(d_mc)){
  d_mc <- d_mc %>% 
    arrange(title) %>% 
    rowid_to_column("id")
  write_csv(d_mc, mc_csv)
}

d_themes <- tibble(
  id = integer(0),
  theme = character(0))

themes <- list.files("tmp", "\\.csv$") %>% 
  str_replace("\\.csv$", "")

themes %>% paste(collapse = "\n") %>% cat()
for (thm in themes){ # thm = themes[1]
  d_themes <- bind_rows(
    d_themes,
    d_mc %>% 
      inner_join(
        read_csv(glue("tmp/{thm}.csv")) %>% 
          mutate(
            theme = thm), by = "title") %>% 
      select(id, theme))
}
write_csv(d_themes, mc_themes_csv)

if (!"themes" %in% names(d_mc) | redo){
  d_mc <- d_mc %>% 
    left_join(
      d_themes %>% 
        arrange(id, theme) %>% 
        group_by(id) %>% 
        summarize(
          themes = paste(theme, collapse = "; ")),
      by = "id")
  write_csv(d_mc, mc_csv)
  
  d_mc %>% 
    filter(is.na(themes)) %>% 
    write_csv(mc_nothemes_csv)
    
  mc_themes_csv
}
d_mc        <- read_csv(mc_csv)
d_mc_themes <- read_csv(mc_themes_csv)
d_mc_themsuppl <- read_csv(mc_supplthemes_csv)

datatable(d_mc %>% select(id, title, themes))
```


## Choose Datasets

* [r - DT collapse all row groups by default - Stack Overflow](https://stackoverflow.com/questions/66761304/dt-collapse-all-row-groups-by-default/66774002#66774002)
* [javascript - Collapse rowGroup Shiny - Stack Overflow](https://stackoverflow.com/questions/59896704/collapse-rowgroup-shiny)
* [Collapse rowGroup · Issue #759 · rstudio/DT](https://github.com/rstudio/DT/issues/759#issuecomment-578854246)
* [DataTables Extensions](https://rstudio.github.io/DT/extensions.html)

- "BOEM Block Aliquots"
- "Outer Continental Shelf Lands Act"

## Download Datasets

```{r download}
mc = read_csv(mc_csv) %>%
  mutate(
    downloads = str_split(downloads, fixed('|')),
    metadatas = str_split(metadatas, fixed('|'))) %>% 
  filter(
    title %in% c(
      "Benthic Cover",
      "Essential Fish Habitat (EFH)",
      "Habitat Areas of Particular Concern"))

for (i in 1:nrow(mc)){ # i=1
  dir_i = file.path(dir_mc, str_replace_all(mc$title[i], '[:/]','-'))
  
  if (dir.exists(dir_i)){
    message('  Output directory exists, so skipping\n')
    next
  }
  
  cat(sprintf('i=%03d: %s\n', i, basename(dir_i)))
  dir.create(dir_i, showWarnings = F, recursive = T)
  
  for (j in 1:length(mc$downloads[[i]])){ # j=1
    down  = mc$downloads[[i]][j]
    dest  = file.path(dir_i, basename(down))
    dir_j = file.path(dir_i, sprintf('%s_dir', tools::file_path_sans_ext(basename(down))))
    err_j = file.path(dir_i, sprintf('%s_error.txt', tools::file_path_sans_ext(basename(down))))

    cat(sprintf('  j=%d: %s\n', j, basename(down)))
    r = try({
      download.file(down, dest)
      dir.create(dir_j, showWarnings = F)
      unzip(dest, exdir=dir_j)
    })
    
    if ('try-error' %in% class(r)){
      write_file(as.character(r), err_j)
    }
  }
}

# show size of files ----
d = read_csv(mc_csv) %>%
  mutate(
    dir_path = file.path(dir_mc, str_replace_all(title, '[:/]','-')),
    dir_base = basename(dir_path),
    dir_size_mb = map_dbl(dir_path, function(p){
      list.files(p, all.files=T, full.names=T, recursive=T) %>%
        file.info() %>% .$size %>% sum(na.rm=T) / (1000*1000)
      }),
    dir_size_mb  = round(dir_size_mb, digits=2))

write_csv(d, mc_paths_csv)

d %>%
  select(title, dir_base, dir_size_mb) %>%
  mutate(
    dir_size_mb = scales::comma(dir_size_mb)) %>%
  datatable(options = list(pageLength = 50))
```

## test read of EFH

```{r}
library(sf)


d_shp <- "/share/data/marinecadastre.gov/Essential Fish Habitat (EFH)/nationwide_efh_dir/nationwide_efh.shp"

d <- read_sf(d_shp)
# d %>% st_drop_geometry() %>% View()

mapview::mapview(d)

```


## connect to database

```{r db_connect}
# connect to database
library(DBI)
library(RPostgres)

pass <- readLines("/share/.password_mhk-env.us")
con  <- DBI::dbConnect(
  RPostgres::Postgres(),
  dbname   = "gis",
  host     = "postgis",
  port     = 5432,
  user     = "admin",
  password = pass)

tbls <- dbListTables(con)
tbls
```

## datasets_marinecadastre.gov.csv - Google Sheet

Read the Google Sheet into a data frame in R.

```{r}
source(here::here("functions.R"))

# datasets_marinecadastre.gov.csv - Google Sheet
#   edit online: https://docs.google.com/spreadsheets/d/1MMVqPr39R5gAyZdY2iJIkkIdYqgEBJYQeGqDk1z-RKQ/edit#gid=0
datasets_gid      <- "1MMVqPr39R5gAyZdY2iJIkkIdYqgEBJYQeGqDk1z-RKQ"
datasets_csv      <- glue("https://docs.google.com/spreadsheets/d/{datasets_gid}/gviz/tq?tqx=out:csv&sheet=datasets")
datasets_mc_csv   <- glue("https://docs.google.com/spreadsheets/d/{datasets_gid}/gviz/tq?tqx=out:csv&sheet=datasets_mc}")

redo_datasets    <- F
redo_datasets_mc <- F

datasets <- read_csv(datasets_csv) %>% 
  select(-starts_with("X"))

datasets_mc <- read_csv(datasets_mc_csv) %>% 
  select(-starts_with("X"))

if (!"datasets" %in% dbListTables(con) | redo_datasets){
  #dbSendQuery(con, "DROP TABLE IF EXISTS datasets_mc CASCADE;")
  #dbGetQuery(con, 'DROP TABLE IF EXISTS "Pacific Northwest Physiographic Habitat - V4_0_SGH_WA_OR_NCA.sh" CASCADE;')
  #dbGetQuery(con, 'DROP TABLE IF EXISTS "Pacific North~ | V4_0_SGH_WA_OR_NCA.shp" CASCADE;')
  #dbGetQuery(con, 'ALTER TABLE datasets RENAME TO datasets_0pre_mc;')
  dbWriteTable(con, "datasets", datasets)
}

if (!"datasets_mc" %in% dbListTables(con) | redo_datasets_mc)
  dbWriteTable(con, "datasets_mc", datasets_mc)

dataset_shps <- datasets_mc %>% 
  select(title, dir_path) %>% # TODO: where did dir_path go?
  mutate(
    # TODO: 
    # - raster: cd /share/data/marinecadastre.gov; find . -type f -name "*.tif"
    # - other?: missing *.shp or *.tif, so *.mdb or error like: cd /share/data/marinecadastre.gov; ls *Turtle* # NA_error.txt
    tif_lst = map(
      dir_path,
      function(x){
        list.files(x, ".*\\.tif$", recursive = T, full.names = T) }),
    )
    shps_lst = map(
      dir_path, 
      function(x){
        list.files(x, ".*\\.shp$", recursive = T, full.names = T) }),
    shps_n = map_int(shps_lst, length)) %>% 
  filter(shps_n > 0) %>%
  rename(shp_path = shps_lst) %>% 
  unnest(shp_path) %>% 
  mutate(
    shp_tbl              = map_chr(shp_path, shp2tbl),
    shp_tbl_duplicated   = duplicated(shp_tbl)) %>% 
  arrange(title, shp_tbl)

if (!"dataset_shps" %in% dbListTables(con) | redo_datasets_mc){
  dbWriteTable(con, "dataset_shps", dataset_shps)
}

shp_tbls_dupes <- dataset_shps %>% 
  filter(shp_tbl_duplicated) %>% 
  distinct(shp_tbl) %>% 
  pull(shp_tbl)

# show duplicates: shp_tbl, title
dataset_shps %>% 
  filter(shp_tbl %in% shp_tbls_dupes) %>% 
  select(shp_tbl, title) %>% 
  arrange(shp_tbl, title)

stopifnot(sum(d_shps$shp_tbl_duplicated) == 0)
stopifnot(sum(d_shps$shp_tbl_duplicated) == 0)

# d_shps %>%
#   select(
#     shp_tbl, shp_tbl_duplicated, 
#     title, shp_fname, priority, 
#     dataset_code, shps_n, dir_size_mb, shp_size_mb,  shp_path) %>%
#   View()

s_shps <- d_shps %>%
  group_by(shp_fname) %>%
  nest() %>% 
  mutate(
    n_rows = map_int(data, nrow)) %>% 
  arrange(desc(n_rows))

# TODO: just load based on shapfile name, update dataset_vectors with lookups shp to dataset
#View(s_shps)

dataset_shps4db <- dataset_shps %>% 
  filter(!shp_tbl_duplicated) %>% 
  select(
    tbl = shp_tbl,
    shp = shp_path) %>% 
  arrange(tbl)

dataset_shps4db %>% 
  pwalk(shp2db)

# d_shps %>%
#   DT::datatable(options = list(pageLength = 50))
```


## Reading gdb: Federal and State Waters

This is an Esri geodatabase (*.gdb) 

```{r}
gdb <- "/share/data/marinecadastre.gov/Federal and State Waters/FederalAndStateWaters_dir/FederalAndStateWaters.gdb"

source(here::here("functions.R"))

library(sf)

sf::st_layers(gdb)
# Driver: OpenFileGDB 
# Available layers:
#              layer_name geometry_type features fields
# 1 FederalAndStateWaters Multi Polygon       40      6
# plys <- sf::read_sf(gdb, lyr)

lyr <- "FederalAndStateWaters"
tbl <- "gdb_FederalAndStateWaters"
gdb2db(gdb, lyr, tbl)
  
dbListTables(con) %>% sort()
```

